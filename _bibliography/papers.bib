
@INPROCEEDINGS{Sandhaus2018-el,
title = "A {WOZ} Study of Feedforward Information on an Ambient Display in Autonomous Cars",
booktitle = "The 31st Annual {ACM} Symposium on User Interface Software and Technology Adjunct Proceedings",
author = "Sandhaus, Hauke and Hornecker, Eva",
abstract = "We describe the development and user testing of an ambient display for autonomous vehicles. Instead of providing feedback about driving actions, once executed, it communicates driving decisions in advance, via light signals in passengers`` peripheral vision. This ambient display was tested in an WoZ-based on-the-road-driving simulation of a fully autonomous vehicle. Findings from a preliminary study with 14 participants suggest that such a display might be particularly useful to communicate upcoming inertia changes for passengers.",
publisher = "Association for Computing Machinery",
pages = "90--92",
series = "UIST '18 Adjunct",
month =  oct,
year =  2018,
url = "https://doi.org/10.1145/3266037.3266111",
address = "New York, NY, USA",
keywords = "on-road simulation, autonomous vehicle interfaces, methodology, ambient display",
location = "Berlin, Germany",
isbn = "9781450359498",
doi = "10.1145/3266037.3266111",
selected={true},
preview={AV_ceiling.png},
html={https://dl.acm.org/doi/10.1145/3266037.3266111}
}


@ARTICLE{Martinez2018-xc,
title = "Smart textiles in the performing arts",
author = "Martinez, A and Honauer, M and Sandhaus, H and Hornecker, E",
abstract = "We present the Sonification Costume, an interactive costume created for modern dance performances, that makes movements perceivable through sound. We created it in the context of studying textile-based sensors, and here describe the exploration of different production techniques, which led to a knitted whole-body suit with seamlessly integrated stretch sensors. Self-reflection and a user study reveal that the costume concept is interesting to dancers and how we can further improve textile-integrated sensors.",
journal = "Textiles, Identity and",
publisher = "taylorfrancis.com",
year =  2018,
url = "https://www.taylorfrancis.com/chapters/edit/10.1201/9781315100210-57/smart-textiles-performing-arts-aline-martinez-michaela-honauer-hauke-sandhaus-eva-hornecker",
selected={true},
preview={dancer.png},
html={https://www.taylorfrancis.com/chapters/edit/10.1201/9781315100210-57/smart-textiles-performing-arts-aline-martinez-michaela-honauer-hauke-sandhaus-eva-hornecker}
}


@MASTERSTHESIS{Sandhaus2015-in,
title = "Development of a {3D} navigable interface for a touchless showcase",
author = "Sandhaus, Hauke Gregor Wilhelm",
abstract = "Due to widespread usage of touchscreens users have accepted interaction without haptic feedback. Commercial game consoles have introduced users to touchless input and natural user interfaces. Only recently it has become technical possible to track human hand skeleton in high detail, precision and low latency contactless. This report describes the design process for the user experience, user interface and interaction interface of a touchless showcase using skeletal hand tracking. The project extends on existing hardware, compares current approaches, researches on the user group and rebuilds the software, based on these findings, from scratch. To allow input, multiple interactions and 3D buttons were developed. In a user experiment these were tested. A final prototype was implemented on two showcases for a month and compared to the existing software. The findings suggest that users want more natural and direct interactions. Missing physical feedback, non-existent depth perception on traditional screens and unfamiliar gesture language are hindrances but can be overcome with the use of good visual cues. Future work on the software is solely on refinement. Some of the interactions investigated in this thesis will prevail, while some might appear in other contexts.",
year =  2015,
school = "University of Twente",
selected={true},
preview={hand_gesture.png},
html={https://essay.utwente.nl/70885/}
}
