@article{sandhaus_student_2024,
	title        = {Student {Reflections} on {Self}-{Initiated} {GenAI} {Use} in {HCI} {Education}},
	author       = {Sandhaus, Hauke and Parreira, Maria Teresa and Ju, Wendy},
	year         = 2024,
	month        = may,
	journal      = {Dark Patterns Workshop at CHI conference},
	location     = {Honolulu, Hawai‘i, USA},
	abstract     = {This study explores students’ self-initiated use of Generative Artificial Intelligence (GenAI) tools in an interactive systems design class. Through 12 group interviews, students revealed the dual nature of GenAI in (1) stimulating creativity and (2) speeding up design iterations, alongside concerns over its potential to cause shallow learning and reliance. GenAI’s benefits were pronounced in the execution phase of design, aiding rapid prototyping and ideation, while its use in initial insight generation posed risks to depth and reflective practice. This reflection highlights the complex role of GenAI in Human-Computer Interaction education, emphasizing the need for balanced integration to leverage its advantages without compromising fundamental learning outcomes.},
	language     = {en},
	preview      = {GenAI-Diamond.png},
	bibtex_show  = {true},
	selected     = {true},
	pdf          = {Sandhaus_2024_CHI_WS_LLMs_in_HCI_Research.pdf}
}
@article{rhomberg_towards_2024,
	title        = {Towards {Quantifying} {Ethical} {User} {Experience}: {Evaluating} {User} {Perceptions} of {Dark} {Patterns} in {Social} {Media}},
	author       = {Rhomberg, Doris Maria and Sandhaus, Hauke},
	year         = 2024,
	month        = may,
	journal      = {Dark Patterns Workshop at CHI conference},
	location     = {Honolulu, Hawai‘i, USA},
	abstract     = {No standardized questionnaire currently incorporates an ethical dimension for assessing User Experience (UX). We explored how the ethicality of interface design is reflected in current UX metrics and how they could be extended. To this end, we adapted the User Experience Questionnaire (UEQ) and enriched it with supplementary items specifically designed to capture user responses on social media to unethical interface designs, commonly referred to as ’dark patterns’. Through an exploratory analysis of a survey involving 120 participants who evaluated a selection of 15 social media dark patterns, we found preliminary evidence that (1) an aggregated UX score using items from the User Experience Questionnaire does not effectively indicate unethical user interface design. Instead, (2) subscale measures from the questionnaire show a relationship with unethical design. Furthermore, extending the User Experience Questionnaire seems promising, as (3) users can identify interfaces with addictive and pressuring properties, and (4) evaluations demonstrate consistency within groups of unethical design strategies.},
	language     = {en},
	pdf          = {Rhomberg_Sandhaus_2024_CHI_WS_Quantifying_Ethical_UX.pdf},
	bibtex_show  = {true},
	preview      = {Ethical_UEQ.png},
	selected     = {true},
	file         = {Rhomberg and Sandhaus - Towards Quantifying Ethical User Experience  Ev.pdf:/Users/hgs52/Zotero/storage/27XU4Z77/Rhomberg and Sandhaus - Towards Quantifying Ethical User Experience  Ev.pdf:application/pdf}
}

@article{Harvey2024-gn,
	title        = {The cadaver in the machine: The social practices of measurement and validation in motion capture technology},
	author       = {Harvey, Emma and Sandhaus, Hauke and Jacobs, Abigail Z and Moss, Emanuel and Sloane, Mona},
	year         = 2024,
	month        = jan,
	arxiv        = {2401.10877},
	archiveprefix = {arXiv},
	primaryclass = {cs.CY},
	bibtex_show  = {true},
	preview      = {Cadaver.png},
	selected     = {true},
	abstract     = {Motion capture systems, used across various domains, make body representations concrete through technical processes. We argue that the measurement of bodies and the validation of measurements for motion capture systems can be understood as social practices. By analyzing the findings of a systematic literature review (N=278) through the lens of social practice theory, we show how these practices, and their varying attention to errors, become ingrained in motion capture design and innovation over time. Moreover, we show how contemporary motion capture systems perpetuate assumptions about human bodies and their movements. We suggest that social practices of measurement and validation are ubiquitous in the development of data- and sensor-driven systems more broadly, and provide this work as a basis for investigating hidden design assumptions and their potential negative consequences in human-computer interaction.}
}
@inproceedings{Kim2023-no,
	title        = {VR job interview using a gender-swapped avatar},
	author       = {Kim, Jieun and Sandhaus, Hauke and Fussell, Susan R},
	year         = 2023,
	month        = oct,
	booktitle    = {Computer Supported Cooperative Work and Social Computing},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	doi          = {10.1145/3584931.3606976},
	url          = {https://doi.org/10.1145/3584931.3606976},
	language     = {en},
	arxiv        = {2307.04247},
	eprint       = {2307.04247},
	archiveprefix = {arXiv},
	primaryclass = {cs.HC},
	howpublished = {CSCW '23 Companion},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {VR_Interview.png},
	abstract     = {Virtual Reality (VR) has emerged as a potential solution for mitigating bias in a job interview by hiding the applicants' demographic features. The current study examines the use of a gender-swapped avatar in a virtual job interview that affects the applicants' perceptions and their performance evaluated by recruiters. With a mixed-method approach, we first conducted a lab experiment (N=8) exploring how using a gender-swapped avatar in a virtual job interview impacts perceived anxiety, confidence, competence, and ability to perform. Then, a semi-structured interview investigated the participants' VR interview experiences using an avatar. Our findings suggest that using gender-swapped avatars may reduce the anxiety that job applicants will experience during the interview. Also, the affinity diagram produced seven key themes highlighting the advantages and limitations of VR as an interview platform. These findings contribute to the emerging field of VR-based recruitment and have practical implications for promoting diversity and inclusion in the hiring process.}
}
@misc{sandhaus2023promoting,
	title        = {Promoting Bright Patterns},
	author       = {Hauke Sandhaus},
	year         = 2023,
	website      = {https://brightpatterns.org/},
	arxiv        = {2304.01157},
	eprint       = {2304.01157},
	archiveprefix = {arXiv},
	primaryclass = {cs.HC},
	howpublished = {CHI '23 Workshop: Designing Technology and Policy Simultaneously},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {Patterns.png},
	abstract     = {User experience designers are facing increasing scrutiny and criticism for creating harmful technologies, leading to a pushback against unethical design practices. While clear-cut harmful practices such as dark patterns have received attention, trends towards automation, personalization, and recommendation present more ambiguous ethical challenges. To address potential harm in these "gray" instances, we propose the concept of "bright patterns" - persuasive design solutions that prioritize user goals and well-being over their desires and business objectives. The ambition of this paper is threefold: to define the term "bright patterns", to provide examples of such patterns, and to advocate for the adoption of bright patterns through policymaking.}
}
@misc{sandhaus2023prototyping,
	title        = {Towards Prototyping Driverless Vehicle Behaviors, City Design, and Policies Simultaneously},
	author       = {Hauke Sandhaus and Wendy Ju and Qian Yang},
	year         = 2023,
	arxiv        = {2304.06639},
	eprint       = {2304.06639},
	archiveprefix = {arXiv},
	primaryclass = {cs.HC},
	howpublished = {CHI '23 Workshop: Designing Technology and Policy Simultaneously},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {AV_Policy_Design.png},
	abstract     = {Autonomous Vehicles (AVs) can potentially improve urban living by reducing accidents, increasing transportation accessibility and equity, and decreasing emissions. Realizing these promises requires the innovations of AV driving behaviors, city plans and infrastructure, and traffic and transportation policies to join forces. However, the complex interdependencies among AV, city, and policy design issues can hinder their innovation. We argue the path towards better AV cities is not a process of matching city designs and policies with AVs' technological innovations, but a process of iterative prototyping of all three simultaneously: Innovations can happen step-wise as the knot of AV, city, and policy design loosens and tightens, unwinds and reties." In this paper, we ask: How can innovators innovate AVs, city environments, and policies simultaneously and productively toward better AV cities? The paper has two parts. First, we map out the interconnections among the many AV, city, and policy design decisions, based on a literature review spanning HCI/HRI, transportation science, urban studies, law and policy, operations research, economy, and philosophy. This map can help innovators identify design constraints and opportunities across the traditional AV/city/policy design disciplinary bounds. Second, we review the respective methods for AV, city, and policy design, and identify key barriers in combining them: (1) Organizational barriers to AV-city-policy design collaboration, (2) computational barriers to multi-granularity AV-city-policy simulation, and (3) different assumptions and goals in joint AV-city-policy optimization. We discuss two broad approaches that can potentially address these challenges, namely, "low-fidelity integrative City-AV-Policy Simulation (iCAPS)" and "participatory design optimization".}
}
@inproceedings{Sandhaus2018-el,
	title        = {A {WOZ} Study of Feedforward Information on an Ambient Display in Autonomous Cars},
	author       = {Sandhaus, Hauke and Hornecker, Eva},
	year         = 2018,
	month        = oct,
	booktitle    = {The 31st Annual {ACM} Symposium on User Interface Software and Technology Adjunct Proceedings},
	location     = {Berlin, Germany},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {UIST '18 Adjunct},
	pages        = {90--92},
	doi          = {10.1145/3266037.3266111},
	isbn         = 9781450359498,
	url          = {https://doi.org/10.1145/3266037.3266111},
	abstract     = {We describe the development and user testing of an ambient display for autonomous vehicles. Instead of providing feedback about driving actions, once executed, it communicates driving decisions in advance, via light signals in passengers`` peripheral vision. This ambient display was tested in an WoZ-based on-the-road-driving simulation of a fully autonomous vehicle. Findings from a preliminary study with 14 participants suggest that such a display might be particularly useful to communicate upcoming inertia changes for passengers.},
	keywords     = {on-road simulation, autonomous vehicle interfaces, methodology, ambient display},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {AV_ceiling.png},
	html         = {https://dl.acm.org/doi/10.1145/3266037.3266111}
}
@article{Martinez2018-xc,
	title        = {Smart textiles in the performing arts},
	author       = {Martinez, Aline and Honauer, Michaela and Sandhaus, Hauke and Hornecker, Eva},
	year         = 2018,
	journal      = {Textiles, Identity and Innovation: Design the Future},
	publisher    = {taylorfrancis.com},
	url          = {https://www.taylorfrancis.com/chapters/edit/10.1201/9781315100210-57/smart-textiles-performing-arts-aline-martinez-michaela-honauer-hauke-sandhaus-eva-hornecker},
	abstract     = {We present the Sonification Costume, an interactive costume created for modern dance performances, that makes movements perceivable through sound. We created it in the context of studying textile-based sensors, and here describe the exploration of different production techniques, which led to a knitted whole-body suit with seamlessly integrated stretch sensors. Self-reflection and a user study reveal that the costume concept is interesting to dancers and how we can further improve textile-integrated sensors.},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {dancer.png},
	html         = {https://www.taylorfrancis.com/chapters/edit/10.1201/9781315100210-57/smart-textiles-performing-arts-aline-martinez-michaela-honauer-hauke-sandhaus-eva-hornecker}
}
@mastersthesis{Sandhaus2015-in,
	title        = {Development of a {3D} navigable interface for a touchless showcase},
	author       = {Sandhaus, Hauke},
	year         = 2015,
	abstract     = {Due to widespread usage of touchscreens users have accepted interaction without haptic feedback. Commercial game consoles have introduced users to touchless input and natural user interfaces. Only recently it has become technical possible to track human hand skeleton in high detail, precision and low latency contactless. This report describes the design process for the user experience, user interface and interaction interface of a touchless showcase using skeletal hand tracking. The project extends on existing hardware, compares current approaches, researches on the user group and rebuilds the software, based on these findings, from scratch. To allow input, multiple interactions and 3D buttons were developed. In a user experiment these were tested. A final prototype was implemented on two showcases for a month and compared to the existing software. The findings suggest that users want more natural and direct interactions. Missing physical feedback, non-existent depth perception on traditional screens and unfamiliar gesture language are hindrances but can be overcome with the use of good visual cues. Future work on the software is solely on refinement. Some of the interactions investigated in this thesis will prevail, while some might appear in other contexts.},
	school       = {University of Twente},
	selected     = {true},
	bibtex_show  = {true},
	preview      = {hand_gesture.png},
	html         = {https://essay.utwente.nl/70885/}
}
